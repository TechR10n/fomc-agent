{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOMC Data Pipeline - Productivity Analysis\n",
    "\n",
    "This notebook loads BLS and DataUSA data from S3 and generates three reports:\n",
    "1. Population statistics (mean & std dev, 2013-2018)\n",
    "2. Best year by series_id\n",
    "3. Series + Population join for PRS30006032 Q01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "spark = SparkSession.builder.appName('FOMC-Analysis').master('local[*]').getOrCreate()\n",
    "print(f'Spark version: {spark.version}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analytics.reports import load_population_from_s3, load_bls_from_s3\n",
    "\n",
    "pop_df = load_population_from_s3(spark)\n",
    "bls_df = load_bls_from_s3(spark)\n",
    "\n",
    "print(f'Population records: {pop_df.count()}')\n",
    "print(f'BLS records: {bls_df.count()}')\n",
    "\n",
    "pop_df.show()\n",
    "bls_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report 1: Population Statistics (2013-2018)\n",
    "\n",
    "Calculate mean and standard deviation of annual US population for years 2013-2018 inclusive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analytics.reports import report_population_stats\n",
    "\n",
    "pop_stats = report_population_stats(pop_df)\n",
    "print(f\"Population Statistics (2013-2018):\")\n",
    "print(f\"  Mean:   {pop_stats['mean']:,.0f}\")\n",
    "print(f\"  StdDev: {pop_stats['stddev']:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report 2: Best Year by Series ID\n",
    "\n",
    "For every series_id, find the year with the largest sum of quarterly values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analytics.reports import report_best_year_by_series\n",
    "\n",
    "best_year_df = report_best_year_by_series(bls_df)\n",
    "print(f'Series with best years: {best_year_df.count()}')\n",
    "best_year_df.orderBy('series_id').show(50, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report 3: Series + Population Join\n",
    "\n",
    "Join BLS data (series_id=PRS30006032, period=Q01) with population data by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analytics.reports import report_series_population_join\n",
    "\n",
    "join_df = report_series_population_join(bls_df, pop_df)\n",
    "join_df.orderBy('year').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Quality & Sync History\n",
    "\n",
    "Load sync logs from S3 and visualize data pipeline health."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from src.helpers.aws_client import get_client\n",
    "\n",
    "s3 = get_client('s3')\n",
    "\n",
    "def load_sync_log(bucket, prefix):\n",
    "    \"\"\"Load sync log JSONL from S3.\"\"\"\n",
    "    key = f'{prefix}sync_log.jsonl'\n",
    "    try:\n",
    "        response = s3.get_object(Bucket=bucket, Key=key)\n",
    "        lines = response['Body'].read().decode().strip().split('\\n')\n",
    "        return [json.loads(line) for line in lines if line.strip()]\n",
    "    except Exception as e:\n",
    "        print(f'Could not load {bucket}/{key}: {e}')\n",
    "        return []\n",
    "\n",
    "bls_log = load_sync_log('fomc-bls-raw', '_sync_state/pr/')\n",
    "datausa_log = load_sync_log('fomc-datausa-raw', '_sync_state/')\n",
    "\n",
    "print(f'BLS sync log entries: {len(bls_log)}')\n",
    "print(f'DataUSA sync log entries: {len(datausa_log)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Chart 1: Sync Timeline\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Parse timestamps and actions\n",
    "if bls_log:\n",
    "    bls_dates = []\n",
    "    bls_actions = Counter()\n",
    "    for entry in bls_log:\n",
    "        ts = entry.get('timestamp', '')\n",
    "        action = entry.get('action', 'unknown')\n",
    "        bls_actions[action] += 1\n",
    "        if ts:\n",
    "            bls_dates.append(datetime.fromisoformat(ts.replace('Z', '+00:00')))\n",
    "\n",
    "    ax = axes[0, 0]\n",
    "    ax.bar(bls_actions.keys(), bls_actions.values(), color=['#2ecc71', '#3498db', '#e74c3c', '#95a5a6'])\n",
    "    ax.set_title('Chart 1: BLS Sync Actions')\n",
    "    ax.set_ylabel('Count')\n",
    "else:\n",
    "    axes[0, 0].text(0.5, 0.5, 'No BLS sync data', ha='center', va='center')\n",
    "    axes[0, 0].set_title('Chart 1: BLS Sync Actions')\n",
    "\n",
    "# Chart 2: Data Freshness\n",
    "ax = axes[0, 1]\n",
    "sources = []\n",
    "days_since = []\n",
    "now = datetime.now()\n",
    "for log, name in [(bls_log, 'BLS/pr'), (datausa_log, 'DataUSA')]:\n",
    "    if log:\n",
    "        last_ts = max(\n",
    "            (datetime.fromisoformat(e['timestamp'].replace('Z', '+00:00')).replace(tzinfo=None)\n",
    "             for e in log if 'timestamp' in e),\n",
    "            default=None\n",
    "        )\n",
    "        if last_ts:\n",
    "            sources.append(name)\n",
    "            days_since.append((now - last_ts).days)\n",
    "\n",
    "if sources:\n",
    "    colors = ['#2ecc71' if d <= 7 else '#f39c12' if d <= 30 else '#e74c3c' for d in days_since]\n",
    "    ax.barh(sources, days_since, color=colors)\n",
    "    ax.set_xlabel('Days Since Last Sync')\n",
    "    ax.set_title('Chart 2: Data Freshness')\n",
    "else:\n",
    "    ax.text(0.5, 0.5, 'No sync data', ha='center', va='center')\n",
    "    ax.set_title('Chart 2: Data Freshness')\n",
    "\n",
    "# Chart 3: File Size Changes (BLS)\n",
    "ax = axes[1, 0]\n",
    "if bls_log:\n",
    "    file_sizes = defaultdict(list)\n",
    "    for entry in bls_log:\n",
    "        if 'bytes' in entry and 'file' in entry:\n",
    "            file_sizes[entry['file']].append(entry['bytes'])\n",
    "    if file_sizes:\n",
    "        for fname, sizes in list(file_sizes.items())[:5]:\n",
    "            ax.plot(range(len(sizes)), sizes, marker='o', label=fname[:20])\n",
    "        ax.set_title('Chart 3: File Size Changes (BLS)')\n",
    "        ax.set_ylabel('Bytes')\n",
    "        ax.legend(fontsize=7)\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'No file size data', ha='center', va='center')\n",
    "        ax.set_title('Chart 3: File Size Changes')\n",
    "else:\n",
    "    ax.text(0.5, 0.5, 'No BLS sync data', ha='center', va='center')\n",
    "    ax.set_title('Chart 3: File Size Changes')\n",
    "\n",
    "# Chart 4: Update Frequency\n",
    "ax = axes[1, 1]\n",
    "if bls_log:\n",
    "    hours = []\n",
    "    for entry in bls_log:\n",
    "        ts = entry.get('timestamp', '')\n",
    "        if ts and entry.get('action') in ('updated', 'added'):\n",
    "            dt = datetime.fromisoformat(ts.replace('Z', '+00:00'))\n",
    "            hours.append(dt.hour)\n",
    "    if hours:\n",
    "        ax.hist(hours, bins=24, range=(0, 24), color='#3498db', edgecolor='white')\n",
    "        ax.set_xlabel('Hour of Day (UTC)')\n",
    "        ax.set_ylabel('Updates')\n",
    "        ax.set_title('Chart 4: Update Frequency by Hour')\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'No update data', ha='center', va='center')\n",
    "        ax.set_title('Chart 4: Update Frequency')\n",
    "else:\n",
    "    ax.text(0.5, 0.5, 'No sync data', ha='center', va='center')\n",
    "    ax.set_title('Chart 4: Update Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('sync_history.png', dpi=100, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Charts saved to sync_history.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary Table: Current state of all data sources\n",
    "def load_state(bucket, key):\n",
    "    try:\n",
    "        response = s3.get_object(Bucket=bucket, Key=key)\n",
    "        return json.loads(response['Body'].read())\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "bls_state = load_state('fomc-bls-raw', '_sync_state/pr/latest_state.json')\n",
    "datausa_state = load_state('fomc-datausa-raw', '_sync_state/latest_state.json')\n",
    "\n",
    "print(f\"{'Source':<15} {'Last Sync':<22} {'Files':<8} {'Status'}\")\n",
    "print('-' * 60)\n",
    "\n",
    "bls_sync = bls_state.get('last_sync', 'N/A')\n",
    "bls_files = len(bls_state.get('files', {}))\n",
    "print(f\"{'BLS/pr':<15} {str(bls_sync)[:19]:<22} {bls_files:<8} {'Current' if bls_files > 0 else 'No data'}\")\n",
    "\n",
    "du_sync = datausa_state.get('last_sync', 'N/A')\n",
    "du_hash = datausa_state.get('content_hash', 'N/A')\n",
    "print(f\"{'DataUSA':<15} {str(du_sync)[:19]:<22} {'1':<8} {'Current' if du_hash != 'N/A' else 'No data'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()\n",
    "print('Analysis complete.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
