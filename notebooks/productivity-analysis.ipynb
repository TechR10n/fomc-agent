{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOMC Data Pipeline - Productivity Analysis\n",
    "\n",
    "This notebook is an end-to-end walkthrough of the Rearc Data Quest (Parts 1-3) using LocalStack:\n",
    "\n",
    "- Part 1: Republish and keep the BLS `pr` dataset in sync in S3\n",
    "- Part 2: Fetch the DataUSA population API and store the JSON payload in S3\n",
    "- Part 3: Load `pr.data.0.Current` (TSV) + `population.json` into pandas DataFrames and produce:\n",
    "  1. Mean + standard deviation of annual US population (2013-2018)\n",
    "  2. Best year per `series_id` (max sum of quarterly values)\n",
    "  3. Join for `series_id=PRS30006032`, `period=Q01` with population by year\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure LocalStack is running:\n",
    "\n",
    "```bash\n",
    "# Start LocalStack + pre-create buckets/queues\n",
    ".venv/bin/python tools/localstack_up.py\n",
    "\n",
    "# Optional: run the full local pipeline refresh\n",
    ".venv/bin/python tools/localstack_full_refresh.py\n",
    "```\n",
    "\n",
    "The first cell below loads environment variables from `.env.shared` + `.env.localstack`.\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 0: Load LocalStack environment + project paths\n",
    "# This must run BEFORE importing from src.config\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"pyproject.toml\").exists() and (p / \"src\").exists():\n",
    "            return p\n",
    "    raise RuntimeError(f\"Could not find repo root starting from: {start}\")\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "\n",
    "# Make local modules importable (tools/env_loader.py, src/*)\n",
    "sys.path.insert(0, str(REPO_ROOT / \"tools\"))\n",
    "sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "from env_loader import load_localstack_env  # noqa: E402\n",
    "\n",
    "load_localstack_env()\n",
    "\n",
    "print(f\"Repo root: {REPO_ROOT}\")\n",
    "print(f\"AWS_ENDPOINT_URL: {os.environ.get('AWS_ENDPOINT_URL', 'not set (using AWS)')}\")\n",
    "print(f\"FOMC_BUCKET_PREFIX: {os.environ.get('FOMC_BUCKET_PREFIX', 'not set')}\")\n"
   ],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:09:41.581295Z",
     "start_time": "2026-02-09T04:09:41.541944Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: /Users/ryan/Developer/fomc-agent\n",
      "AWS_ENDPOINT_URL: http://localhost:4566\n",
      "FOMC_BUCKET_PREFIX: fomc\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 + Part 2: Sync Raw Data into S3 (LocalStack)\n",
    "\n",
    "This cell runs the same code path as the scheduled Lambda in the AWS/CDK pipeline:\n",
    "\n",
    "- Part 1: sync BLS `pr` files into S3 (keeps in sync with adds/updates/deletes)\n",
    "- Part 2: fetch the DataUSA population API and store the JSON payload in S3\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:09:51.532313Z",
     "start_time": "2026-02-09T04:09:41.607382Z"
    }
   },
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import urllib.request\n",
    "\n",
    "endpoint = os.environ.get('AWS_ENDPOINT_URL', 'http://localhost:4566').rstrip('/')\n",
    "health_url = f\"{endpoint}/_localstack/health\"\n",
    "\n",
    "try:\n",
    "    with urllib.request.urlopen(health_url, timeout=5) as resp:  # nosec - local URL\n",
    "        health = json.loads(resp.read().decode(\"utf-8\", errors=\"replace\"))\n",
    "    print(\"LocalStack is reachable:\", health.get(\"version\", \"unknown\"))\n",
    "except Exception as exc:\n",
    "    raise RuntimeError(\n",
    "        f\"LocalStack does not look reachable at {health_url}. \"\n",
    "        \"Start it with `.venv/bin/python tools/localstack_up.py` and re-run this cell.\"\n",
    "    ) from exc\n",
    "\n",
    "from src.lambdas.data_fetcher.handler import handler as fetcher_handler\n",
    "\n",
    "started = time.time()\n",
    "response = fetcher_handler({}, None)\n",
    "duration_seconds = time.time() - started\n",
    "\n",
    "body = response.get(\"body\")\n",
    "if isinstance(body, str):\n",
    "    try:\n",
    "        body = json.loads(body)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(json.dumps({\"duration_seconds\": round(duration_seconds, 2), \"response\": {**response, \"body\": body}}, indent=2, default=str))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"duration_seconds\": 9.91,\n",
      "  \"response\": {\n",
      "    \"statusCode\": 200,\n",
      "    \"body\": {\n",
      "      \"bls\": {\n",
      "        \"pr\": {\n",
      "          \"updated\": [],\n",
      "          \"added\": [],\n",
      "          \"unchanged\": [\n",
      "            \"pr.data.0.Current\"\n",
      "          ],\n",
      "          \"deleted\": []\n",
      "        },\n",
      "        \"cu\": {\n",
      "          \"updated\": [],\n",
      "          \"added\": [],\n",
      "          \"unchanged\": [\n",
      "            \"cu.data.0.Current\"\n",
      "          ],\n",
      "          \"deleted\": []\n",
      "        },\n",
      "        \"jt\": {\n",
      "          \"updated\": [],\n",
      "          \"added\": [],\n",
      "          \"unchanged\": [\n",
      "            \"jt.data.0.Current\"\n",
      "          ],\n",
      "          \"deleted\": []\n",
      "        },\n",
      "        \"ci\": {\n",
      "          \"updated\": [],\n",
      "          \"added\": [],\n",
      "          \"unchanged\": [\n",
      "            \"ci.data.0.Current\"\n",
      "          ],\n",
      "          \"deleted\": []\n",
      "        }\n",
      "      },\n",
      "      \"datausa\": {\n",
      "        \"datasets\": {\n",
      "          \"population\": {\n",
      "            \"action\": \"skipped\",\n",
      "            \"dataset_id\": \"population\",\n",
      "            \"key\": \"population.json\"\n",
      "          },\n",
      "          \"commute_time\": {\n",
      "            \"action\": \"skipped\",\n",
      "            \"dataset_id\": \"commute_time\",\n",
      "            \"key\": \"commute_time.json\"\n",
      "          },\n",
      "          \"citizenship\": {\n",
      "            \"action\": \"skipped\",\n",
      "            \"dataset_id\": \"citizenship\",\n",
      "            \"key\": \"citizenship.json\"\n",
      "          }\n",
      "        },\n",
      "        \"errors\": []\n",
      "      },\n",
      "      \"errors\": []\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:09:51.581357Z",
     "start_time": "2026-02-09T04:09:51.554982Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.config import bls_data_key, get_bls_bucket, get_datausa_bucket, get_datausa_key\n",
    "\n",
    "BLS_BUCKET = get_bls_bucket()\n",
    "BLS_KEY = bls_data_key(\"pr\", \"pr.data.0.Current\")  # Quest Part 1\n",
    "DATAUSA_BUCKET = get_datausa_bucket()\n",
    "POP_KEY = get_datausa_key()  # Quest Part 2\n",
    "\n",
    "print(f\"BLS raw:     s3://{BLS_BUCKET}/{BLS_KEY}\")\n",
    "print(f\"DataUSA raw: s3://{DATAUSA_BUCKET}/{POP_KEY}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLS raw:     s3://fomc-bls-raw/pr/pr.data.0.Current\n",
      "DataUSA raw: s3://fomc-datausa-raw/population.json\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data from S3"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:09:51.741213Z",
     "start_time": "2026-02-09T04:09:51.582221Z"
    }
   },
   "source": [
    "from IPython.display import display\n",
    "from src.analytics.reports import load_population_from_s3, load_bls_from_s3\n",
    "\n",
    "pop_df = load_population_from_s3(bucket=DATAUSA_BUCKET, key=POP_KEY)\n",
    "bls_df = load_bls_from_s3(bucket=BLS_BUCKET, key=BLS_KEY)\n",
    "\n",
    "print(f'Population rows: {len(pop_df)}')\n",
    "print(f'BLS rows: {len(bls_df)}')\n",
    "\n",
    "display(pop_df.head())\n",
    "display(bls_df.head())\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     series_id  year period  value footnote_codes\n",
       "0  PRS30006011  1995    Q01    2.6            NaN\n",
       "1  PRS30006011  1995    Q02    2.1            NaN\n",
       "2  PRS30006011  1995    Q03    0.9            NaN\n",
       "3  PRS30006011  1995    Q04    0.1            NaN\n",
       "4  PRS30006011  1995    Q05    1.4            NaN"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "      <th>footnote_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRS30006011</td>\n",
       "      <td>1995</td>\n",
       "      <td>Q01</td>\n",
       "      <td>2.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRS30006011</td>\n",
       "      <td>1995</td>\n",
       "      <td>Q02</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRS30006011</td>\n",
       "      <td>1995</td>\n",
       "      <td>Q03</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRS30006011</td>\n",
       "      <td>1995</td>\n",
       "      <td>Q04</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRS30006011</td>\n",
       "      <td>1995</td>\n",
       "      <td>Q05</td>\n",
       "      <td>1.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report 1: Population Statistics (2013-2018)\n",
    "\n",
    "Calculate mean and standard deviation of annual US population for years 2013-2018 inclusive."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:09:51.872923Z",
     "start_time": "2026-02-09T04:09:51.812348Z"
    }
   },
   "source": [
    "from src.analytics.reports import report_population_stats\n",
    "\n",
    "pop_stats = report_population_stats(pop_df)\n",
    "print(f\"Population Statistics (2013-2018):\")\n",
    "print(f\"  Mean:   {pop_stats['mean']:,.0f}\")\n",
    "print(f\"  StdDev: {pop_stats['stddev']:,.0f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population Statistics (2013-2018):\n",
      "  Mean:   322,069,808\n",
      "  StdDev: 4,158,441\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report 2: Best Year by Series ID\n",
    "\n",
    "For every series_id, find the year with the largest sum of quarterly values."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:09:51.951459Z",
     "start_time": "2026-02-09T04:09:51.873686Z"
    }
   },
   "source": [
    "from IPython.display import display\n",
    "from src.analytics.reports import report_best_year_by_series\n",
    "\n",
    "best_year_rows = report_best_year_by_series(bls_df)\n",
    "best_year_df = pd.DataFrame(best_year_rows).sort_values('series_id').reset_index(drop=True)\n",
    "print(f'Series with best years: {len(best_year_df)}')\n",
    "display(best_year_df.head(32))"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      series_id  year  value\n",
       "0   PRS30006011  2022   20.5\n",
       "1   PRS30006012  2022   17.1\n",
       "2   PRS30006013  1998  705.9\n",
       "3   PRS30006021  2010   17.7\n",
       "4   PRS30006022  2010   12.4\n",
       "5   PRS30006023  2014  503.2\n",
       "6   PRS30006031  2022   20.5\n",
       "7   PRS30006032  2021   17.1\n",
       "8   PRS30006033  1998  702.7\n",
       "9   PRS30006061  2022   34.5\n",
       "10  PRS30006062  2021   29.8\n",
       "11  PRS30006063  2024  643.5\n",
       "12  PRS30006081  2021   24.5\n",
       "13  PRS30006082  2021   24.5\n",
       "14  PRS30006083  2022  131.3\n",
       "15  PRS30006091  2002   43.4\n",
       "16  PRS30006092  2002   44.3\n",
       "17  PRS30006093  2013  514.2\n",
       "18  PRS30006101  2020   33.1\n",
       "19  PRS30006102  2020   35.7\n",
       "20  PRS30006103  2024  641.7\n",
       "21  PRS30006111  2020   33.8\n",
       "22  PRS30006112  2008   42.0\n",
       "23  PRS30006113  2024  659.8\n",
       "24  PRS30006131  2021   18.6\n",
       "25  PRS30006132  2021   18.6\n",
       "26  PRS30006133  2022  132.8\n",
       "27  PRS30006151  2020   26.2\n",
       "28  PRS30006152  2020   30.5\n",
       "29  PRS30006153  2020  529.3\n",
       "30  PRS30006161  2010   50.5\n",
       "31  PRS30006162  2002   48.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>year</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRS30006011</td>\n",
       "      <td>2022</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRS30006012</td>\n",
       "      <td>2022</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRS30006013</td>\n",
       "      <td>1998</td>\n",
       "      <td>705.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRS30006021</td>\n",
       "      <td>2010</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRS30006022</td>\n",
       "      <td>2010</td>\n",
       "      <td>12.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PRS30006023</td>\n",
       "      <td>2014</td>\n",
       "      <td>503.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRS30006031</td>\n",
       "      <td>2022</td>\n",
       "      <td>20.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2021</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PRS30006033</td>\n",
       "      <td>1998</td>\n",
       "      <td>702.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PRS30006061</td>\n",
       "      <td>2022</td>\n",
       "      <td>34.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PRS30006062</td>\n",
       "      <td>2021</td>\n",
       "      <td>29.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PRS30006063</td>\n",
       "      <td>2024</td>\n",
       "      <td>643.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PRS30006081</td>\n",
       "      <td>2021</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PRS30006082</td>\n",
       "      <td>2021</td>\n",
       "      <td>24.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PRS30006083</td>\n",
       "      <td>2022</td>\n",
       "      <td>131.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PRS30006091</td>\n",
       "      <td>2002</td>\n",
       "      <td>43.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PRS30006092</td>\n",
       "      <td>2002</td>\n",
       "      <td>44.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PRS30006093</td>\n",
       "      <td>2013</td>\n",
       "      <td>514.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PRS30006101</td>\n",
       "      <td>2020</td>\n",
       "      <td>33.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PRS30006102</td>\n",
       "      <td>2020</td>\n",
       "      <td>35.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PRS30006103</td>\n",
       "      <td>2024</td>\n",
       "      <td>641.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PRS30006111</td>\n",
       "      <td>2020</td>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PRS30006112</td>\n",
       "      <td>2008</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PRS30006113</td>\n",
       "      <td>2024</td>\n",
       "      <td>659.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PRS30006131</td>\n",
       "      <td>2021</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PRS30006132</td>\n",
       "      <td>2021</td>\n",
       "      <td>18.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PRS30006133</td>\n",
       "      <td>2022</td>\n",
       "      <td>132.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PRS30006151</td>\n",
       "      <td>2020</td>\n",
       "      <td>26.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PRS30006152</td>\n",
       "      <td>2020</td>\n",
       "      <td>30.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PRS30006153</td>\n",
       "      <td>2020</td>\n",
       "      <td>529.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PRS30006161</td>\n",
       "      <td>2010</td>\n",
       "      <td>50.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>PRS30006162</td>\n",
       "      <td>2002</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report 3: Series + Population Join\n",
    "\n",
    "Join BLS data (series_id=PRS30006032, period=Q01) with population data by year."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:09:52.196546Z",
     "start_time": "2026-02-09T04:09:52.021320Z"
    }
   },
   "source": [
    "from IPython.display import display\n",
    "from src.analytics.reports import report_series_population_join\n",
    "\n",
    "join_rows = report_series_population_join(bls_df, pop_df)\n",
    "join_df = pd.DataFrame(join_rows).sort_values('year').reset_index(drop=True)\n",
    "display(join_df)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      series_id  year period  value   Population\n",
       "0   PRS30006032  1995    Q01    0.0          NaN\n",
       "1   PRS30006032  1996    Q01   -4.2          NaN\n",
       "2   PRS30006032  1997    Q01    2.8          NaN\n",
       "3   PRS30006032  1998    Q01    0.9          NaN\n",
       "4   PRS30006032  1999    Q01   -4.1          NaN\n",
       "5   PRS30006032  2000    Q01    0.5          NaN\n",
       "6   PRS30006032  2001    Q01   -6.3          NaN\n",
       "7   PRS30006032  2002    Q01   -6.6          NaN\n",
       "8   PRS30006032  2003    Q01   -5.7          NaN\n",
       "9   PRS30006032  2004    Q01    2.0          NaN\n",
       "10  PRS30006032  2005    Q01   -0.5          NaN\n",
       "11  PRS30006032  2006    Q01    1.8          NaN\n",
       "12  PRS30006032  2007    Q01   -0.8          NaN\n",
       "13  PRS30006032  2008    Q01   -3.5          NaN\n",
       "14  PRS30006032  2009    Q01  -21.0          NaN\n",
       "15  PRS30006032  2010    Q01    3.2          NaN\n",
       "16  PRS30006032  2011    Q01    1.5          NaN\n",
       "17  PRS30006032  2012    Q01    2.5          NaN\n",
       "18  PRS30006032  2013    Q01    0.5  316128839.0\n",
       "19  PRS30006032  2014    Q01   -0.1  318857056.0\n",
       "20  PRS30006032  2015    Q01   -1.7  321418821.0\n",
       "21  PRS30006032  2016    Q01   -1.4  323127515.0\n",
       "22  PRS30006032  2017    Q01    0.9  325719178.0\n",
       "23  PRS30006032  2018    Q01    0.5  327167439.0\n",
       "24  PRS30006032  2019    Q01   -1.6  328239523.0\n",
       "25  PRS30006032  2020    Q01   -7.0          NaN\n",
       "26  PRS30006032  2021    Q01    0.7  331893745.0\n",
       "27  PRS30006032  2022    Q01    5.3  333287562.0\n",
       "28  PRS30006032  2023    Q01    0.3  334914896.0\n",
       "29  PRS30006032  2024    Q01   -0.7          NaN\n",
       "30  PRS30006032  2025    Q01    0.4          NaN"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>series_id</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>1995</td>\n",
       "      <td>Q01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>1996</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>1997</td>\n",
       "      <td>Q01</td>\n",
       "      <td>2.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>1998</td>\n",
       "      <td>Q01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>1999</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2000</td>\n",
       "      <td>Q01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2001</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-6.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2002</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2003</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2004</td>\n",
       "      <td>Q01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2005</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2006</td>\n",
       "      <td>Q01</td>\n",
       "      <td>1.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2007</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2008</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2009</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-21.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2010</td>\n",
       "      <td>Q01</td>\n",
       "      <td>3.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2011</td>\n",
       "      <td>Q01</td>\n",
       "      <td>1.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2012</td>\n",
       "      <td>Q01</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2013</td>\n",
       "      <td>Q01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>316128839.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2014</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>318857056.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2015</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>321418821.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2016</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>323127515.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2017</td>\n",
       "      <td>Q01</td>\n",
       "      <td>0.9</td>\n",
       "      <td>325719178.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2018</td>\n",
       "      <td>Q01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>327167439.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2019</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>328239523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2020</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2021</td>\n",
       "      <td>Q01</td>\n",
       "      <td>0.7</td>\n",
       "      <td>331893745.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2022</td>\n",
       "      <td>Q01</td>\n",
       "      <td>5.3</td>\n",
       "      <td>333287562.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2023</td>\n",
       "      <td>Q01</td>\n",
       "      <td>0.3</td>\n",
       "      <td>334914896.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2024</td>\n",
       "      <td>Q01</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>PRS30006032</td>\n",
       "      <td>2025</td>\n",
       "      <td>Q01</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Data Quality & Sync History\n",
    "\n",
    "Load sync logs from S3 and visualize data pipeline health."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:09:52.322157Z",
     "start_time": "2026-02-09T04:09:52.236582Z"
    }
   },
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "from src.config import get_bls_bucket, get_datausa_bucket, get_datausa_datasets\n",
    "from src.helpers.aws_client import get_client\n",
    "\n",
    "s3 = get_client(\"s3\")\n",
    "\n",
    "def _is_missing_key(exc: Exception) -> bool:\n",
    "    if not isinstance(exc, ClientError):\n",
    "        return False\n",
    "    code = str(exc.response.get(\"Error\", {}).get(\"Code\", \"\")).strip()\n",
    "    return code in {\"404\", \"NoSuchKey\", \"NotFound\"}\n",
    "\n",
    "def load_jsonl(bucket: str, key: str) -> list[dict]:\n",
    "    try:\n",
    "        response = s3.get_object(Bucket=bucket, Key=key)\n",
    "    except Exception as exc:\n",
    "        if _is_missing_key(exc):\n",
    "            return []\n",
    "        raise\n",
    "    lines = response[\"Body\"].read().decode(\"utf-8\", errors=\"replace\").splitlines()\n",
    "    out: list[dict] = []\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        try:\n",
    "            out.append(json.loads(line))\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "    return out\n",
    "\n",
    "# BLS sync logs are stored per-series\n",
    "bls_series_id = \"pr\"\n",
    "bls_log = load_jsonl(get_bls_bucket(), f\"_sync_state/{bls_series_id}/sync_log.jsonl\")\n",
    "\n",
    "# DataUSA sync logs are stored per-dataset\n",
    "datausa_bucket = get_datausa_bucket()\n",
    "datausa_datasets = get_datausa_datasets(default=\"population\")\n",
    "datausa_logs_by_dataset = {\n",
    "    ds: load_jsonl(datausa_bucket, f\"_sync_state/datausa/{ds}/sync_log.jsonl\")\n",
    "    for ds in datausa_datasets\n",
    "}\n",
    "\n",
    "datausa_log: list[dict] = []\n",
    "for ds, logs in datausa_logs_by_dataset.items():\n",
    "    for entry in logs:\n",
    "        e = dict(entry)\n",
    "        e.setdefault(\"dataset_id\", ds)\n",
    "        datausa_log.append(e)\n",
    "\n",
    "print(f'BLS sync log entries (pr): {len(bls_log)}')\n",
    "print(f'DataUSA sync log entries (all datasets): {len(datausa_log)}')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLS sync log entries (pr): 10\n",
      "DataUSA sync log entries (all datasets): 30\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:09:52.583393Z",
     "start_time": "2026-02-09T04:09:52.323398Z"
    }
   },
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "# Chart 1: BLS/pr Sync Actions\n",
    "# Chart 2: Data Freshness (BLS + each DataUSA dataset)\n",
    "# Chart 3: File Size Changes (BLS)\n",
    "# Chart 4: Update Frequency (BLS)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Chart 1\n",
    "if bls_log:\n",
    "    actions = Counter(e.get(\"action\", \"unknown\") for e in bls_log)\n",
    "    ax = axes[0, 0]\n",
    "    ax.bar(actions.keys(), actions.values(), color=[\"#2ecc71\", \"#3498db\", \"#e74c3c\", \"#95a5a6\"])\n",
    "    ax.set_title(\"Chart 1: BLS/pr Sync Actions\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "else:\n",
    "    axes[0, 0].text(0.5, 0.5, \"No BLS sync data\", ha=\"center\", va=\"center\")\n",
    "    axes[0, 0].set_title(\"Chart 1: BLS/pr Sync Actions\")\n",
    "\n",
    "def _parse_ts(ts: str):\n",
    "    try:\n",
    "        from datetime import datetime\n",
    "        return datetime.fromisoformat(ts.replace(\"Z\", \"+00:00\")).replace(tzinfo=None)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def _last_ts(logs: list[dict]):\n",
    "    dts = []\n",
    "    for e in logs:\n",
    "        ts = e.get(\"timestamp\")\n",
    "        if not ts:\n",
    "            continue\n",
    "        dt = _parse_ts(ts)\n",
    "        if dt is not None:\n",
    "            dts.append(dt)\n",
    "    return max(dts) if dts else None\n",
    "\n",
    "# Chart 2\n",
    "ax = axes[0, 1]\n",
    "sources = []\n",
    "days_since = []\n",
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "pairs = [(bls_log, \"BLS/pr\")] + [(logs, f\"DataUSA/{ds}\") for ds, logs in sorted(datausa_logs_by_dataset.items())]\n",
    "for logs, name in pairs:\n",
    "    last = _last_ts(logs)\n",
    "    if last is None:\n",
    "        continue\n",
    "    sources.append(name)\n",
    "    days_since.append((now - last).days)\n",
    "\n",
    "if sources:\n",
    "    colors = [\"#2ecc71\" if d <= 7 else \"#f39c12\" if d <= 30 else \"#e74c3c\" for d in days_since]\n",
    "    ax.barh(sources, days_since, color=colors)\n",
    "    ax.set_xlabel(\"Days Since Last Sync\")\n",
    "    ax.set_title(\"Chart 2: Data Freshness\")\n",
    "else:\n",
    "    ax.text(0.5, 0.5, \"No sync data\", ha=\"center\", va=\"center\")\n",
    "    ax.set_title(\"Chart 2: Data Freshness\")\n",
    "\n",
    "# Chart 3: File Size Changes (BLS)\n",
    "ax = axes[1, 0]\n",
    "if bls_log:\n",
    "    file_sizes = defaultdict(list)\n",
    "    for entry in bls_log:\n",
    "        if \"bytes\" in entry and \"file\" in entry:\n",
    "            file_sizes[entry[\"file\"]].append(entry[\"bytes\"])\n",
    "    if file_sizes:\n",
    "        for fname, sizes in list(file_sizes.items())[:5]:\n",
    "            ax.plot(range(len(sizes)), sizes, marker=\"o\", label=fname[:20])\n",
    "        ax.set_title(\"Chart 3: File Size Changes (BLS)\")\n",
    "        ax.set_ylabel(\"Bytes\")\n",
    "        ax.legend(fontsize=7)\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, \"No file size data\", ha=\"center\", va=\"center\")\n",
    "        ax.set_title(\"Chart 3: File Size Changes\")\n",
    "else:\n",
    "    ax.text(0.5, 0.5, \"No BLS sync data\", ha=\"center\", va=\"center\")\n",
    "    ax.set_title(\"Chart 3: File Size Changes\")\n",
    "\n",
    "# Chart 4: Update Frequency (BLS)\n",
    "ax = axes[1, 1]\n",
    "if bls_log:\n",
    "    hours = []\n",
    "    for entry in bls_log:\n",
    "        ts = entry.get(\"timestamp\", \"\")\n",
    "        if not ts or entry.get(\"action\") not in (\"updated\", \"added\"):\n",
    "            continue\n",
    "        dt = _parse_ts(ts)\n",
    "        if dt is not None:\n",
    "            hours.append(dt.hour)\n",
    "    if hours:\n",
    "        ax.hist(hours, bins=24, range=(0, 24), color=\"#3498db\", edgecolor=\"white\")\n",
    "        ax.set_xlabel(\"Hour of Day (UTC)\")\n",
    "        ax.set_ylabel(\"Updates\")\n",
    "        ax.set_title(\"Chart 4: Update Frequency by Hour\")\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, \"No update data\", ha=\"center\", va=\"center\")\n",
    "        ax.set_title(\"Chart 4: Update Frequency\")\n",
    "else:\n",
    "    ax.text(0.5, 0.5, \"No sync data\", ha=\"center\", va=\"center\")\n",
    "    ax.set_title(\"Chart 4: Update Frequency\")\n",
    "\n",
    "plt.tight_layout()\n",
    "out_path = REPO_ROOT / \"notebooks\" / \"sync_history.png\"\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(out_path, dpi=100, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(f\"Charts saved to {out_path}\")\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ps/w0lhnvdx18q56b22jssvm70w0000gn/T/ipykernel_38538/1079295389.py:112: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:09:52.618401Z",
     "start_time": "2026-02-09T04:09:52.584276Z"
    }
   },
   "source": [
    "# Summary Table: Current state of all data sources\n",
    "def load_state_json(bucket: str, key: str) -> dict:\n",
    "    try:\n",
    "        response = s3.get_object(Bucket=bucket, Key=key)\n",
    "        return json.loads(response[\"Body\"].read())\n",
    "    except Exception:\n",
    "        return {}\n",
    "\n",
    "from src.config import get_bls_bucket, get_datausa_bucket, get_datausa_datasets\n",
    "\n",
    "bls_state = load_state_json(get_bls_bucket(), \"_sync_state/pr/latest_state.json\")\n",
    "datausa_bucket = get_datausa_bucket()\n",
    "datausa_states = {\n",
    "    ds: load_state_json(datausa_bucket, f\"_sync_state/datausa/{ds}/latest_state.jsonl\")\n",
    "    for ds in get_datausa_datasets(default=\"population\")\n",
    "}\n",
    "\n",
    "print(\"{:<25} {:<22} {:<10} {}\".format(\"Source\", \"Last Sync\", \"Items\", \"Status\"))\n",
    "print(\"-\" * 72)\n",
    "\n",
    "bls_sync = bls_state.get(\"last_sync\", \"N/A\")\n",
    "bls_files = len(bls_state.get(\"files\", {}) or {})\n",
    "print(\"{:<25} {:<22} {:<10} {}\".format(\"BLS/pr\", str(bls_sync)[:19], bls_files, \"Current\" if bls_files > 0 else \"No data\"))\n",
    "\n",
    "for ds, state in sorted(datausa_states.items()):\n",
    "    last_sync = state.get(\"last_sync\", \"N/A\")\n",
    "    record_count = state.get(\"record_count\")\n",
    "    items = record_count if isinstance(record_count, int) else \"N/A\"\n",
    "    status = \"Current\" if state.get(\"content_hash\") else \"No data\"\n",
    "    print(\"{:<25} {:<22} {:<10} {}\".format(\"DataUSA/\" + ds, str(last_sync)[:19], str(items), status))\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source                    Last Sync              Items      Status\n",
      "------------------------------------------------------------------------\n",
      "BLS/pr                    2026-02-09T04:09:41    1          Current\n",
      "DataUSA/citizenship       2026-02-09T03:32:19    20         Current\n",
      "DataUSA/commute_time      2026-02-09T03:32:14    48334      Current\n",
      "DataUSA/population        2026-02-09T03:32:13    10         Current\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T04:09:52.634187Z",
     "start_time": "2026-02-09T04:09:52.619880Z"
    }
   },
   "source": [
    "print('Analysis complete.')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis complete.\n"
     ]
    }
   ],
   "execution_count": 56
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
