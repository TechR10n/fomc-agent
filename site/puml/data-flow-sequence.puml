@startuml data-flow-sequence
!theme plain
skinparam shadowing false


title FOMC Agent - End-to-End AWS Data Flow Sequence\n(Scheduler, ingestion, queueing, analytics, and site delivery)

participant "EventBridge\nFetchScheduleRule" as EB #E3F2FD
participant "Lambda\nfomc-data-fetcher" as Fetcher #E3F2FD
participant "BLS LABSTAT\ndownload.bls.gov" as BLS #F5F5F5
participant "DataUSA API\napi.datausa.io" as DataUSA #F5F5F5
database "S3\n{prefix}-bls-raw" as S3_BLS #E8F5E9
database "S3\n{prefix}-datausa-raw" as S3_DATAUSA #E8F5E9
queue "SQS\n{FOMC_ANALYTICS_QUEUE_NAME}" as Q #FFF3E0
queue "SQS DLQ\n{FOMC_ANALYTICS_DLQ_NAME}" as DLQ #FFEBEE
participant "Lambda\nfomc-analytics-processor" as Analytics #FFF3E0
participant "CloudWatch Logs" as Logs #F5F5F5

== 1) Scheduled ingestion trigger ==
EB -> Fetcher : invoke (rate: FOMC_FETCH_INTERVAL_HOURS)
activate Fetcher

== 2) BLS raw sync into S3 ==
Fetcher -> S3_BLS : get _sync_state/{series}/latest_state.json
S3_BLS --> Fetcher : previous sync state
Fetcher -> BLS : GET /pub/time.series/{series}/
BLS --> Fetcher : directory listing

loop changed or new files
  Fetcher -> BLS : GET /pub/time.series/{series}/{filename}
  BLS --> Fetcher : file bytes
  Fetcher -> S3_BLS : put {series}/{filename}\nmetadata: source_modified
  Fetcher -> S3_BLS : append _sync_state/{series}/sync_log.jsonl
end

loop removed files
  Fetcher -> S3_BLS : delete {series}/{filename}
  Fetcher -> S3_BLS : append sync log (action=deleted)
end

Fetcher -> S3_BLS : save latest_state.json (temp write -> copy -> delete temp)

== 3) DataUSA raw sync into S3 ==
loop configured datasets (population, commute_time, citizenship, ...)
  Fetcher -> DataUSA : GET /tesseract/data.jsonrecords?...dataset params...
  DataUSA --> Fetcher : JSON payload
  Fetcher -> Fetcher : compute content hash

  alt content changed
    Fetcher -> S3_DATAUSA : put {dataset}.json\nmetadata: content_hash
    Fetcher -> S3_DATAUSA : save _sync_state/datausa/{dataset}/latest_state.jsonl
    Fetcher -> S3_DATAUSA : append sync_log.jsonl (updated)
  else unchanged or interval skip
    Fetcher -> S3_DATAUSA : append sync_log.jsonl (unchanged/skipped)
  end
end

Fetcher -> Logs : emit execution summary logs
Fetcher --> EB : return {statusCode, results, errors}
deactivate Fetcher

== 4) S3 event fan-out to SQS ==
S3_DATAUSA -> Q : S3 notification\nOBJECT_CREATED + suffix=.json
note over Q
  Visibility timeout: 6 minutes
  DLQ configured after 3 receives
end note

== 5) Queue-driven analytics ==
Q -> Analytics : Lambda event source mapping (batch_size=1)
activate Analytics
Analytics -> S3_DATAUSA : get population.json
S3_DATAUSA --> Analytics : JSON data
Analytics -> S3_BLS : get {BLS_KEY}\n(default: pr/pr.data.0.Current)
S3_BLS --> Analytics : tab-separated BLS data
Analytics -> Analytics : generate report_1, report_2, report_3
Analytics -> Logs : logger.info(report results)

alt success
  Analytics --> Q : ack/delete message
else failure (retries exhausted)
  Q -> DLQ : move message after max_receive_count=3
end

deactivate Analytics

== 6) Static site publish + delivery ==
actor "Developer" as Dev
participant "CDK BucketDeployment" as Deploy #F3E5F5
database "S3\n{prefix}-site" as S3_SITE #F3E5F5
participant "CloudFront" as CF #F3E5F5
actor "Browser User" as User

Dev -> Deploy : cdk deploy FomcSiteStack
Deploy -> S3_SITE : upload site/* (HTML/CSS/JS/data)
Deploy -> CF : invalidate /*
User -> CF : HTTPS GET /index.html, /data/*.json
CF -> S3_SITE : origin fetch
S3_SITE --> CF : static objects
CF --> User : cached responses

@enduml
