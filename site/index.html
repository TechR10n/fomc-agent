<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Dashboard — FOMC Agent Lab</title>
  <link rel="stylesheet" href="style.css" />
</head>
<body>
  <nav>
    <a class="brand" href="index.html">FOMC Agent Lab</a>
    <a class="active" href="index.html">Dashboard</a>
    <a href="pipeline.html">Pipeline</a>
    <a href="timeline.html">Timeline</a>
    <a href="charts.html">Charts</a>
    <a href="architecture.html">Architecture</a>
    <a href="design.html">Design</a>
    <a href="alternatives.html">Alternatives</a>
    <a href="diagrams.html">Diagrams</a>
    <a href="about.html">About</a>
    <a href="bls-guide.html">BLS Guide</a>
    <a href="adr.html">ADRs</a>
  </nav>

  <div class="container">
    <div class="page-header">
      <h1>Data Pipeline Dashboard</h1>
      <p class="subtitle">A 4-step demo pipeline (raw → parse/update → enrich → CDC) that works the same way in LocalStack and AWS.</p>
    </div>

    <!-- Environment toggle -->
    <div class="card">
      <div class="env-toggle" role="tablist" aria-label="Environment selector">
        <button class="env-tab" type="button" data-env="localstack" aria-selected="true">LocalStack</button>
        <button class="env-tab" type="button" data-env="aws" aria-selected="false">AWS Cloud</button>
      </div>
      <p class="muted" style="margin-top:0.75rem;">
        The dashboard below swaps commands and resource names depending on the selected environment.
        In both cases, <strong>ingestion only lands raw data</strong> — parsing, enrichment, and CDC are separate steps.
      </p>
    </div>

    <!-- Live-ish status (static JSON on the site) -->
    <div class="grid-3">
      <div class="card stat">
        <div class="number" id="dash-last-run">—</div>
        <div class="label">Last Run</div>
      </div>
      <div class="card stat">
        <div class="number" id="dash-files-checked">—</div>
        <div class="label">Files Checked</div>
      </div>
      <div class="card stat">
        <div class="number" id="dash-files-updated">—</div>
        <div class="label">Files Updated</div>
      </div>
    </div>

    <!-- Four-step dashboard -->
    <div class="grid-2">
      <div class="card step step-1">
        <div class="step-head">
          <div>
            <div class="kicker">Step 1</div>
            <h2>Ingest Raw</h2>
            <p class="muted">Download source data and land it in raw buckets <em>without parsing</em>.</p>
          </div>
          <span class="badge badge-green">raw</span>
        </div>
        <div class="pill-row">
          <span class="pill">BLS LABSTAT flat files</span>
          <span class="pill">DataUSA population API</span>
          <span class="pill">S3 raw buckets</span>
        </div>

        <div class="only-localstack">
          <h3>LocalStack demo</h3>
          <pre><code>docker compose up -d
source .env.localstack
python tools/localstack_invoke_fetcher.py

# verify raw landed
aws --endpoint-url=http://localhost:4566 s3 ls s3://fomc-bls-raw/pr/ --recursive | head
aws --endpoint-url=http://localhost:4566 s3 ls s3://fomc-datausa-raw/</code></pre>
        </div>

        <div class="only-aws">
          <h3>AWS demo</h3>
          <pre><code>source .env.local   # contains FOMC_BUCKET_PREFIX + AWS_PROFILE
npx cdk deploy --all --require-approval never

# run ingestion now (scheduled daily at 09:00 UTC too)
aws lambda invoke --function-name fomc-data-fetcher /tmp/fetcher.json --profile "$AWS_PROFILE"
cat /tmp/fetcher.json</code></pre>
        </div>
      </div>

      <div class="card step step-2">
        <div class="step-head">
          <div>
            <div class="kicker">Step 2</div>
            <h2>Parse &amp; Update</h2>
            <p class="muted">Convert raw objects into clean, queryable “silver” tables and update the current view.</p>
          </div>
          <span class="badge badge-blue">silver</span>
        </div>
        <div class="pill-row">
          <span class="pill">Schema + cleaning</span>
          <span class="pill">Idempotent upserts</span>
          <span class="pill">S3 silver buckets</span>
        </div>

        <div class="only-localstack">
          <h3>LocalStack demo</h3>
          <p class="muted">Ingest once, then iterate quickly on parsing without re-downloading the sources.</p>
          <pre><code>source .env.localstack
python -m src.transforms.to_silver

aws --endpoint-url=http://localhost:4566 s3 ls s3://fomc-bls-silver/pr/ --recursive | head
aws --endpoint-url=http://localhost:4566 s3 ls s3://fomc-datausa-silver/</code></pre>
        </div>

        <div class="only-aws">
          <h3>AWS demo</h3>
          <p class="muted">For the demo, you can run parsing locally against AWS S3 (production would run this as a separate job/Lambda).</p>
          <pre><code>source .env.local
python -m src.transforms.to_silver

aws s3 ls s3://$FOMC_BUCKET_PREFIX-bls-silver/pr/ --recursive --profile "$AWS_PROFILE" | head
aws s3 ls s3://$FOMC_BUCKET_PREFIX-datausa-silver/ --profile "$AWS_PROFILE"</code></pre>
        </div>
      </div>

      <div class="card step step-3">
        <div class="step-head">
          <div>
            <div class="kicker">Step 3</div>
            <h2>Enrich</h2>
            <p class="muted">Join and derive analytics-ready datasets (e.g., BLS series × population by year).</p>
          </div>
          <span class="badge badge-amber">gold</span>
        </div>
        <div class="pill-row">
          <span class="pill">Joins</span>
          <span class="pill">Aggregations</span>
          <span class="pill">Publish JSON for charts</span>
        </div>

        <div class="only-localstack">
          <h3>LocalStack demo</h3>
          <pre><code>source .env.localstack

# run analytics locally against LocalStack S3
python -m src.analytics.reports</code></pre>
        </div>

        <div class="only-aws">
          <h3>AWS demo</h3>
          <pre><code># Enrichment is typically a separate compute step:
# - Lambda (stdlib CSV/JSON) for small workloads
# - Glue / EMR / Athena for bigger workloads
# - Outputs written to a "gold" bucket or directly to a serving store</code></pre>
        </div>
      </div>

      <div class="card step step-4">
        <div class="step-head">
          <div>
            <div class="kicker">Step 4</div>
            <h2>CDC &amp; Triggers</h2>
            <p class="muted">Capture changes and fan-out work with durable events (S3 → SQS → workers).</p>
          </div>
          <span class="badge badge-gray">events</span>
        </div>
        <div class="pill-row">
          <span class="pill">S3 notifications</span>
          <span class="pill">SQS (DLQ)</span>
          <span class="pill">At-least-once processing</span>
        </div>

        <div class="only-localstack">
          <h3>LocalStack demo</h3>
          <pre><code>source .env.localstack

# 1) start a local worker that polls SQS and runs the Lambda handler
python tools/localstack_worker.py

# 2) in another terminal, "touch" DataUSA to trigger S3 -> SQS
python tools/localstack_touch_datausa.py</code></pre>
        </div>

        <div class="only-aws">
          <h3>AWS demo</h3>
          <pre><code># Uploading a new population.json triggers S3 -> SQS
aws s3 cp population.json s3://$FOMC_BUCKET_PREFIX-datausa-raw/population.json --profile "$AWS_PROFILE"

# Then check:
# - SQS queue depth (fomc-analytics-queue)
# - Lambda logs (/aws/lambda/fomc-analytics-processor)</code></pre>
        </div>
      </div>
    </div>

    <div class="card prose">
      <h2>Where this comes from</h2>
      <p>
        The four steps map directly to the workshop requirements in <code>docs/instructions.md</code>:
        ingest raw datasets (BLS + API), then run analytics, and finally automate it with IaC and event-driven compute.
      </p>
      <p class="muted">
        Want more detail? See <a href="architecture.html">Architecture</a> for diagrams and <a href="pipeline.html">Pipeline</a> for the last-run evidence.
      </p>
    </div>
  </div>

  <script>
    // Environment toggle
    (function initEnvToggle() {
      const tabs = Array.from(document.querySelectorAll(".env-tab"));
      const stored = localStorage.getItem("fomc_env");
      const initial = stored === "aws" ? "aws" : "localstack";

      function setEnv(env) {
        document.body.dataset.env = env;
        localStorage.setItem("fomc_env", env);
        for (const t of tabs) {
          const active = t.dataset.env === env;
          t.classList.toggle("active", active);
          t.setAttribute("aria-selected", String(active));
        }
      }

      tabs.forEach(t => t.addEventListener("click", () => setEnv(t.dataset.env)));
      setEnv(initial);
    })();

    // Dashboard stats sourced from the same JSON used on the Pipeline page.
    (async function loadDashboardStats() {
      try {
        const resp = await fetch("data/pipeline_status.json", { cache: "no-store" });
        if (!resp.ok) return;
        const data = await resp.json();
        const lastRun = new Date(data.last_run);
        document.getElementById("dash-last-run").textContent = lastRun.toLocaleDateString();
        document.getElementById("dash-files-checked").textContent = data.summary?.total_files_checked ?? "—";
        document.getElementById("dash-files-updated").textContent = data.summary?.files_updated ?? "—";
      } catch (e) {
        // leave placeholders
      }
    })();
  </script>
</body>
</html>
